{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vocational-editing",
   "metadata": {},
   "source": [
    "# Orthogonal RNN\n",
    "\n",
    "Train Orthogonal RNN for MNIST classification based on [this Paper](https://arxiv.org/pdf/1901.08428.pdf)\n",
    "\n",
    "NOTE: this example is still under development. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-internship",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-cincinnati",
   "metadata": {},
   "source": [
    "For each element in the input sequence, each layer computes the following function:\n",
    "$$h_t=\\tanh(W_{ih}x_t+b_{ih}+W_{hh}h_{t-1}+b_hh)$$\n",
    "\n",
    "where $h_{t}$ is the hidden state at time $t$, and $h_{t-1}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $o$. \n",
    "\n",
    "For each layer, we have the orthogonal constraint:\n",
    "$$ W_{hh}^T W_{hh} = I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-acrylic",
   "metadata": {},
   "source": [
    "## Modules Importing\n",
    "Import all necessary modules and add PyGRANSO src folder to system path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "strange-deputy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "primary-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import sys\n",
    "## Adding PyGRANSO directories. Should be modified by user\n",
    "sys.path.append('/users/5/dever120/PyGRANSO/')\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct \n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from pygranso.private.getObjGrad import getObjGradDL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-seating",
   "metadata": {},
   "source": [
    "## Data Initialization \n",
    "Specify torch device, neural network architecture, and generate data.\n",
    "\n",
    "NOTE: please specify path for downloading data.\n",
    "\n",
    "Use GPU for this problem. If no cuda device available, please set *device = torch.device('cpu')*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 30\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "double_precision = torch.double\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x,(batch_size,sequence_length,input_size))\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=device, dtype=double_precision)\n",
    "        out, hidden = self.rnn(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=double_precision)\n",
    "model.train()\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = '/home/buyun/Documents/GitHub/PyGRANSO/examples/data/mnist',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ") \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, \n",
    "    batch_size=100, \n",
    "    shuffle=True, \n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "loaders = {\n",
    "    'train' : train_loader,\n",
    "}\n",
    "\n",
    "inputs, labels = next(iter(loaders['train']))\n",
    "inputs, labels = (\n",
    "    (\n",
    "        inputs\n",
    "        .reshape(-1, sequence_length, input_size)\n",
    "        .to(device=device, dtype=double_precision)\n",
    "    ),\n",
    "    labels.to(device=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-lexington",
   "metadata": {},
   "source": [
    "## Function Set-Up\n",
    "\n",
    "Encode the optimization variables, and objective and constraint functions.\n",
    "\n",
    "Note: please strictly follow the format of comb_fn, which will be used in the PyGRANSO main algortihm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-chase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_fn(model, inputs, labels):\n",
    "    # objective function\n",
    "    # TODO: autocast would go here but we need a way\n",
    "    # to scale the gradients\n",
    "    logits = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    f = criterion(logits, labels)\n",
    "\n",
    "    A = list(model.parameters())[1]\n",
    "\n",
    "    # inequality constraint\n",
    "    ci = None\n",
    "\n",
    "    # equality constraint \n",
    "    # special orthogonal group\n",
    "    \n",
    "    ce = pygransoStruct()\n",
    "\n",
    "    c1_vec = (\n",
    "        A.T @ A - torch.eye(hidden_size).to(device=device, dtype=double_precision)\n",
    "    ).reshape(1,-1)\n",
    "    \n",
    "    ce.c1 = torch.linalg.vector_norm(c1_vec,2) # l2 folding to reduce the total number of constraints\n",
    "    # ce.c2 = torch.det(A) - 1\n",
    "\n",
    "    # ce = None\n",
    "\n",
    "    return [f,ci,ce]\n",
    "\n",
    "comb_fn = lambda model : user_fn(model,inputs,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-biodiversity",
   "metadata": {},
   "source": [
    "## User Options\n",
    "Specify user-defined options for PyGRANSO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "opts.opt_tol = 1e-3\n",
    "opts.viol_eq_tol = 1e-4\n",
    "# opts.maxit = 150\n",
    "# opts.fvalquit = 1e-6\n",
    "opts.print_level = 1\n",
    "opts.print_frequency = 50\n",
    "# opts.print_ascii = True\n",
    "# opts.limited_mem_size = 100\n",
    "opts.double_precision = True\n",
    "\n",
    "opts.mu0 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-volunteer",
   "metadata": {},
   "source": [
    "## Initial Test \n",
    "Check initial accuracy of the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Initial acc = {:.2f}%\".format((100 * correct/len(inputs))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-vulnerability",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "soln = pygranso(var_spec= model, combined_fn = comb_fn, user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-johnston",
   "metadata": {},
   "source": [
    "## Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.utils.vector_to_parameters(soln.final.x, model.parameters())\n",
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Final acc = {:.2f}%\".format((100 * correct/len(inputs))))  \n",
    "print(\"final feasibility = {}\".format(soln.final.tve))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "materialmind",
   "language": "python",
   "name": "materialmind"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
