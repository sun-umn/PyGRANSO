{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5257bb27",
   "metadata": {},
   "source": [
    "# Orthogonal RNN\n",
    "\n",
    "This notebook contains examples of how to train RNN with otrhogonal constraints.\n",
    "\n",
    "Reference: Lezcano-Casado, Mario, and David Martınez-Rubio. \"Cheap orthogonal constraints in neural networks: A simple parametrization of the orthogonal and unitary group.\" International Conference on Machine Learning. PMLR, 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859c154",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96269c7",
   "metadata": {},
   "source": [
    "$$\\min_{B\\in G}f(B),$$\n",
    "where $f$ is our classifier implemented in RNN, $B$ is the recurrent kernel/matrix, and $G$ is the orthogonal group\n",
    "$$G=\\{ B\\in R^{n\\times n} | B^TB=I, \\det(B)=1 \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfdd50",
   "metadata": {},
   "source": [
    "## Modules Importing\n",
    "Import all necessary modules and add PyGRANSO src folder to system path. PyGRANSO src folder to system path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ed32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import sys\n",
    "## Adding PyGRANSO directories. Should be modified by user\n",
    "sys.path.append('/home/buyun/Documents/GitHub/PyGRANSO')\n",
    "from pygranso import pygranso\n",
    "from pygransoStruct import Options, Data, GeneralStruct \n",
    "from private.getNvar import getNvarTorch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a1b7fe",
   "metadata": {},
   "source": [
    "## Data Generation \n",
    "Specify torch device, neural network architecture, and generate data.\n",
    "\n",
    "NOTE: please specify path for downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4842e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buyun/anaconda3/envs/cuosqp_pygranso/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 30\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=device, dtype=torch.double)\n",
    "        out, hidden = self.rnn(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=torch.double)\n",
    "model.train()\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = '/home/buyun/Documents/GitHub/PyGRANSO/examples/data/mnist',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = False,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = '/home/buyun/Documents/GitHub/PyGRANSO/examples/data/mnist', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                        batch_size=100, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=1),\n",
    "\n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                        batch_size=100, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=1),\n",
    "}\n",
    "\n",
    "inputs, labels = next(iter(loaders['train']))\n",
    "inputs, labels = inputs.reshape(-1, sequence_length, input_size).to(device=device, dtype=torch.double), labels.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80716b",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "\n",
    "Spceify torch device, optimization variables, and corresponding objective and constrained function.\n",
    "\n",
    "Note: please strictly follow the format of evalObjFunction and combinedFunction, which will be used in the PyGRANSO main algortihm. *X_struct* and *data_in* are always required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb360e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables and corresponding dimensions.\n",
    "var_in = {}\n",
    "var_count = 0\n",
    "var_str = \"x\"\n",
    "for i in model.parameters():\n",
    "    # print(i.shape)\n",
    "    var_in[var_str+str(var_count)]= list(i.shape)\n",
    "    var_count += 1\n",
    "\n",
    "def evalObjFunction(X_struct):\n",
    "    var_str = \"x\"\n",
    "    var_count = 0\n",
    "    for p in model.parameters():\n",
    "        tmpstr = var_str+str(var_count)\n",
    "        tmp_parameter = getattr(X_struct,tmpstr)\n",
    "        tmp_parameter.requires_grad_(True)\n",
    "        p.data = tmp_parameter\n",
    "        var_count += 1\n",
    "\n",
    "    logits = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    f = criterion(logits, labels)\n",
    "    return f\n",
    "\n",
    "def combinedFunction(X_struct):\n",
    "    var_str = \"x\"\n",
    "    var_count = 0\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    for p in model.parameters():\n",
    "        tmpstr = var_str+str(var_count)\n",
    "        tmp_parameter = getattr(X_struct,tmpstr)\n",
    "        # Obtain the recurrent parameter with dimension n by n, where n is the number of features in the hidden state h\n",
    "        if tmp_parameter.shape == torch.Size([hidden_size, hidden_size]):\n",
    "            A = tmp_parameter\n",
    "        tmp_parameter.requires_grad_(True)\n",
    "        p.data = tmp_parameter\n",
    "        var_count += 1\n",
    "\n",
    "    logits = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    f = criterion(logits, labels)\n",
    "    # inequality constraint\n",
    "    ci = None\n",
    "\n",
    "    # equality constraint \n",
    "\n",
    "    # special orthogonal group\n",
    "    ce = GeneralStruct()\n",
    "    ce.c1 = A.T @ A - torch.eye(hidden_size).to(device=device, dtype=torch.double)\n",
    "    ce.c2 = torch.det(A) - 1\n",
    "    return [f,ci,ce]\n",
    "\n",
    "obj_eval_fn = lambda X_struct: evalObjFunction(X_struct)\n",
    "comb_fn = lambda X_struct: combinedFunction(X_struct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f55ace",
   "metadata": {},
   "source": [
    "## User Options\n",
    "Specify user-defined options for PyGRANSO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a65b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = Options()\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "opts.QPsolver = 'osqp' \n",
    "opts.maxit = 100\n",
    "opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "opts.opt_tol = 1e-6\n",
    "opts.fvalquit = 1e-6\n",
    "opts.print_level = 1\n",
    "opts.print_frequency = 10\n",
    " # opts.max_fallback_level = 3\n",
    "# opts.min_fallback_level = 2\n",
    "# opts.init_step_size = 1e-2\n",
    "opts.init_step_size = 1e-1\n",
    "opts.halt_on_linesearch_bracket = False\n",
    "# opts.disable_terminationcode_6 = True\n",
    "\n",
    "opts.linesearch_maxit = 25\n",
    "# opts.linesearch_maxit = 10\n",
    "opts.is_backtrack_linesearch = True\n",
    "opts.searching_direction_rescaling = True\n",
    "# opts.limited_mem_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ba30a",
   "metadata": {},
   "source": [
    "## Initial Test \n",
    "Check initial accuracy of RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711f0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial acc = 10.00%\n"
     ]
    }
   ],
   "source": [
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Initial acc = {:.2f}%\".format((100 * correct/len(inputs))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca18c7",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632976b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    ║ \n",
      "Version 1.1.0                                                                                                    ║ \n",
      "MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2110                                                                     ║ \n",
      " # of inequality constraints        :      0                                                                     ║ \n",
      " # of equality constraints          :    901                                                                     ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║ Ineq │    Eq    ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  67.2368561403 ║  2.28955713337 ║   -  │ 1.000000 ║ -  │     1 │ 0.000000 ║     1 │ 2.422980   ║ \n",
      "  10 ║ 1.000000 │  67.4589045448 ║  2.28399989361 ║   -  │ 1.000000 ║ S  │     2 │ 0.100000 ║     1 │ 2.404088   ║ \n",
      "  20 ║ 1.000000 │  68.0595385866 ║  2.27873887846 ║   -  │ 1.000000 ║ S  │     2 │ 0.100000 ║     1 │ 2.389355   ║ \n",
      "  30 ║ 1.000000 │  69.2512726894 ║  2.27383427322 ║   -  │ 1.000000 ║ S  │     2 │ 0.100000 ║     1 │ 2.367721   ║ \n",
      "  40 ║ 1.000000 │  71.3052315175 ║  2.26935323686 ║   -  │ 1.000000 ║ S  │     2 │ 0.100000 ║     1 │ 1.976711   ║ \n",
      "  50 ║ 1.000000 │  74.6814633841 ║  2.26536021921 ║   -  │ 1.000000 ║ S  │     2 │ 0.100000 ║     1 │ 2.273386   ║ \n",
      "  60 ║ 1.000000 │  79.7411695846 ║  2.26189450591 ║   -  │ 1.000000 ║ S  │     2 │ 0.100000 ║     1 │ 2.190910   ║ \n",
      "  70 ║ 1.000000 │  86.2616645255 ║  2.25895023660 ║   -  │ 1.000000 ║ S  │     2 │ 0.100000 ║     1 │ 2.171850   ║ \n",
      "  80 ║ 0.348678 │  91.8764637075 ║  2.22693890045 ║   -  │ 1.000000 ║ \u001b[33mSI\u001b[0m │    28 │ 0.100000 ║     1 │ 0.002079   ║ \n",
      "  90 ║ 0.121577 │  94.9496895765 ║  2.19391755194 ║   -  │ 1.000000 ║ S  │     2 │ 0.100000 ║     1 │ 3.044705   ║ \n",
      " 100 ║ 0.121577 │  97.9882439719 ║  2.12287599622 ║   -  │ 1.000000 ║ S  │     2 │ 0.100000 ║     1 │ 2.839398   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "Optimization results:                                                                                            ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  2.12287599622 ║   -  │ 1.000000 ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  2.25736811653 ║   -  │ 1.000000 ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              100                                                                                     ║ \n",
      "Function evaluations:    331                                                                                     ║ \n",
      "PyGRANSO termination code: 4 --- max iterations reached.                                                         ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "Total Wall Time: 278.3564567565918s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "soln = pygranso(combinedFunction = comb_fn, objEvalFunction = obj_eval_fn,var_dim_map = var_in, nn_model= model, torch_device = device, user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bff5fd",
   "metadata": {},
   "source": [
    "## Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d846f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final acc = 17.00%\n"
     ]
    }
   ],
   "source": [
    "torch.nn.utils.vector_to_parameters(soln.final.x, model.parameters())\n",
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Final acc = {:.2f}%\".format((100 * correct/len(inputs))))     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
