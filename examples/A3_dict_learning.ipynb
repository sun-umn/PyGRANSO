{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "architectural-network",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/5/dever120/PyGRANSO\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-naples",
   "metadata": {},
   "source": [
    "# Dictionary Learning\n",
    "\n",
    "Solve orthogonal dictionary learning problem taken from: Yu Bai, Qijia Jiang, and Ju Sun. \n",
    "[\"Subgradient descent learns orthogonal dictionaries.\"](https://arxiv.org/abs/1810.10702) arXiv preprint arXiv:1810.10702 (2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-friday",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-conducting",
   "metadata": {},
   "source": [
    "Given data $\\{y_i \\}_{i \\in[m]}$ generated as $y_i = A x_i$, where $A \\in R^{n \\times n}$ is a fixed unknown orthogonal matrix and each $x_i \\in R^n$ is an iid Bernoulli-Gaussian random vector with parameter $\\theta \\in (0,1)$, recover $A$. \n",
    "\n",
    "Write $Y \\doteq [y_1,...,y_m]$ and $X \\doteq [x_1,...,x_m]$. To find the column of $A$, one can perform the following optimization:\n",
    "\n",
    "$$\\min_{q \\in R^n} f(q) \\doteq \\frac{1}{m} ||q^T Y||_{1} = \\frac{1}{m} \\sum_{i=1}^m |q^T y_i|,$$\n",
    "$$\\text{s.t.} ||q||_2 = 1$$\n",
    "\n",
    "This problem is nonconvex due to the constraint and nonsmooth due to the objective.\n",
    "\n",
    "Based on the above statistical model, $q^T Y = q^T A X$ has the highest sparsity when $q$ is a column of $A$ (up to sign) so that $q^T A$ is 1-sparse. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-opposition",
   "metadata": {},
   "source": [
    "## Modules Importing\n",
    "Import all necessary modules and add PyGRANSO src folder to system path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "numeric-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy.linalg as la\n",
    "from scipy.stats import norm\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-denmark",
   "metadata": {},
   "source": [
    "## Data Initialization \n",
    "Specify torch device, and generate data\n",
    "\n",
    "Use GPU for this problem. If no cuda device available, please set *device = torch.device('cpu')*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "figured-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "n = 30\n",
    "\n",
    "np.random.seed(1)\n",
    "m = 10*n**2   # sample complexity\n",
    "theta = 0.3   # sparsity level\n",
    "Y = norm.ppf(np.random.rand(n,m)) * (norm.ppf(np.random.rand(n,m)) <= theta)  # Bernoulli-Gaussian model\n",
    "# All the user-provided data (vector/matrix/tensor) must be in torch tensor format. \n",
    "# As PyTorch tensor is single precision by default, one must explicitly set `dtype=torch.double`.\n",
    "# Also, please make sure the device of provided torch tensor is the same as opts.torch_device.\n",
    "Y = torch.from_numpy(Y).to(device=device, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-seller",
   "metadata": {},
   "source": [
    "## Function Set-Up\n",
    "\n",
    "Encode the optimization variables, and objective and constraint functions.\n",
    "\n",
    "Note: please strictly follow the format of comb_fn, which will be used in the PyGRANSO main algortihm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "residential-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables and corresponding dimensions.\n",
    "var_in = {\"q\": [n,1]}\n",
    "\n",
    "\n",
    "def user_fn(X_struct,Y):\n",
    "    q = X_struct.q\n",
    "    \n",
    "    # objective function\n",
    "    qtY = q.T @ Y\n",
    "    f = 1/m * torch.norm(qtY, p = 1)\n",
    "\n",
    "    # inequality constraint, matrix form\n",
    "    ci = None\n",
    "\n",
    "    # equality constraint \n",
    "    ce = pygransoStruct()\n",
    "    ce.c1 = q.T @ q - 1\n",
    "\n",
    "    return [f,ci,ce]\n",
    "\n",
    "comb_fn = lambda X_struct : user_fn(X_struct,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-equity",
   "metadata": {},
   "source": [
    "## User Options\n",
    "Specify user-defined options for PyGRANSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "naval-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "opts.maxit = 500\n",
    "np.random.seed(1)\n",
    "x0 = norm.ppf(np.random.rand(n,1))\n",
    "x0 /= la.norm(x0,2)\n",
    "opts.x0 = torch.from_numpy(x0).to(device=device, dtype=torch.double)\n",
    "\n",
    "opts.print_frequency = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-sunset",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-champion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   30                                                                       ║ \n",
      " # of inequality constraints        :    0                                                                       ║ \n",
      " # of equality constraints          :    1                                                                       ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║ Ineq │    Eq    ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  0.61751624522 ║  0.61751624522 ║   -  │ 3.33e-16 ║ -  │     1 │ 0.000000 ║     1 │ 0.054689   ║ \n",
      "  10 ║ 0.109419 │  0.06725283359 ║  0.61442815347 ║   -  │ 2.27e-05 ║ S  │     3 │ 0.250000 ║     1 │ 0.009922   ║ \n",
      "  20 ║ 0.038152 │  0.02339673542 ║  0.61277911849 ║   -  │ 1.80e-05 ║ S  │     2 │ 2.000000 ║     1 │ 9.90e-04   ║ \n",
      "  30 ║ 0.038152 │  0.02335018544 ║  0.61190277644 ║   -  │ 4.84e-06 ║ S  │     2 │ 2.000000 ║     1 │ 9.83e-04   ║ \n",
      "  40 ║ 0.004175 │  0.00255301126 ║  0.61155490428 ║   -  │ 3.99e-08 ║ S  │     2 │ 0.500000 ║     1 │ 1.34e-04   ║ \n",
      "  50 ║ 0.003381 │  0.00206769656 ║  0.61148781486 ║   -  │ 1.66e-08 ║ S  │     2 │ 0.500000 ║     2 │ 7.95e-05   ║ \n",
      "  60 ║ 0.003381 │  0.00206748427 ║  0.61142557410 ║   -  │ 1.48e-08 ║ S  │     2 │ 0.500000 ║     2 │ 9.18e-05   ║ \n",
      "  70 ║ 0.003381 │  0.00206727722 ║  0.61136433535 ║   -  │ 1.48e-08 ║ S  │     2 │ 0.500000 ║     2 │ 8.99e-05   ║ \n",
      "  80 ║ 0.003381 │  0.00206707181 ║  0.61130341544 ║   -  │ 1.54e-08 ║ S  │     2 │ 0.500000 ║     2 │ 9.24e-05   ║ \n",
      "  90 ║ 0.003381 │  0.00206690438 ║  0.61125217577 ║   -  │ 2.12e-08 ║ S  │     3 │ 0.250000 ║     4 │ 9.09e-05   ║ \n",
      " 100 ║ 0.003381 │  0.00206674144 ║  0.61120769440 ║   -  │ 8.68e-09 ║ \u001b[33mSI\u001b[0m │     1 │ 1.000000 ║     1 │ 1.10e-04   ║ \n",
      " 110 ║ 0.003381 │  0.00206649128 ║  0.61113403156 ║   -  │ 7.60e-09 ║ \u001b[33mSI\u001b[0m │     1 │ 1.000000 ║     1 │ 1.08e-04   ║ \n",
      " 120 ║ 0.003381 │  0.00206624653 ║  0.61106155370 ║   -  │ 7.93e-09 ║ \u001b[33mSI\u001b[0m │     1 │ 1.000000 ║     1 │ 1.08e-04   ║ \n",
      " 130 ║ 0.003381 │  0.00206599947 ║  0.61098833062 ║   -  │ 8.47e-09 ║ \u001b[33mSI\u001b[0m │     1 │ 1.000000 ║     1 │ 1.10e-04   ║ \n",
      " 140 ║ 0.003043 │  0.00185926019 ║  0.61093390781 ║   -  │ 3.39e-08 ║ S  │     2 │ 0.500000 ║     4 │ 8.25e-05   ║ \n",
      " 150 ║ 0.003043 │  0.00185925732 ║  0.61091806828 ║   -  │ 7.92e-08 ║ S  │     3 │ 0.250000 ║     4 │ 8.29e-05   ║ \n",
      " 160 ║ 0.003043 │  0.00185925419 ║  0.61090098994 ║   -  │ 1.28e-07 ║ S  │     2 │ 0.500000 ║     4 │ 8.34e-05   ║ \n",
      " 170 ║ 0.003043 │  0.00185925109 ║  0.61088420596 ║   -  │ 1.76e-07 ║ S  │     2 │ 0.500000 ║     3 │ 8.21e-05   ║ \n",
      " 180 ║ 0.003043 │  0.00185924986 ║  0.61086736264 ║   -  │ 2.26e-07 ║ S  │     2 │ 0.500000 ║     3 │ 8.41e-05   ║ \n",
      " 190 ║ 0.003043 │  0.00185924513 ║  0.61085153491 ║   -  │ 2.70e-07 ║ S  │     3 │ 0.250000 ║     4 │ 8.32e-05   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║ Ineq │    Eq    ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      " 200 ║ 0.003043 │  0.00185924220 ║  0.61083461366 ║   -  │ 3.18e-07 ║ S  │     3 │ 0.250000 ║     4 │ 8.25e-05   ║ \n",
      " 210 ║ 0.003043 │  0.00185924005 ║  0.61081768221 ║   -  │ 3.67e-07 ║ S  │     3 │ 0.250000 ║     4 │ 8.26e-05   ║ \n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn,user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))\n",
    "print(max(abs(soln.final.x))) # should be close to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-arnold",
   "metadata": {},
   "source": [
    "## Various Options\n",
    "\n",
    "**(Optional)** Set fvalquit. Quit if the objective value drops below this value at a feasible \n",
    "iterate (that is, satisfying feasibility tolerances \n",
    "opts.viol_ineq_tol and opts.viol_eq_tol)\n",
    "\n",
    "In the example below, we get termination code 2 since the target objective reached at point feasible to tolerances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "opts.maxit = 500\n",
    "np.random.seed(1)\n",
    "x0 = norm.ppf(np.random.rand(n,1))\n",
    "x0 /= la.norm(x0,2)\n",
    "opts.x0 = torch.from_numpy(x0).to(device=device, dtype=torch.double)\n",
    "opts.print_frequency = 10\n",
    "opts.print_ascii = True\n",
    "\n",
    "\n",
    "opts.fvalquit = 0.4963\n",
    "\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn,user_opts = opts)\n",
    "print(max(abs(soln.final.x))) # should be close to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-investment",
   "metadata": {},
   "source": [
    "Set opt_tol. Tolerance for reaching (approximate) optimality/stationarity.\n",
    "See opts.ngrad, opts.evaldist, and the description of PyGRANSO's \n",
    "output argument soln, specifically the subsubfield .dnorm for more\n",
    "information.\n",
    "\n",
    "In the result below, PyGRANSO terminated when stationarity is below 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device \n",
    "opts.maxit = 500\n",
    "np.random.seed(1)\n",
    "x0 = norm.ppf(np.random.rand(n,1))\n",
    "x0 /= la.norm(x0,2)\n",
    "opts.x0 = torch.from_numpy(x0).to(device=device, dtype=torch.double)\n",
    "opts.print_frequency = 10\n",
    "opts.print_ascii = True\n",
    "\n",
    "opts.opt_tol = 1e-4 # default 1e-8\n",
    "\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn,user_opts = opts)\n",
    "print(max(abs(soln.final.x))) # should be close to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-identification",
   "metadata": {},
   "source": [
    "There are multiple other settings. Please uncomment to try them. Detailed description can be found by typing\n",
    "\n",
    "import pygransoOptionsAdvanced\n",
    "\n",
    "help(pygransoOptionsAdvanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device \n",
    "opts.maxit = 500\n",
    "np.random.seed(1)\n",
    "x0 = norm.ppf(np.random.rand(n,1))\n",
    "x0 /= la.norm(x0,2)\n",
    "opts.x0 = torch.from_numpy(x0).to(device=device, dtype=torch.double)\n",
    "opts.print_frequency = 10\n",
    "\n",
    "# Please uncomment to try different settings\n",
    "\n",
    "# Tolerance for determining when the relative decrease in the penalty\n",
    "# function is sufficiently small.  PyGRANSO will terminate if when \n",
    "# the relative decrease in the penalty function is at or below this\n",
    "# tolerance and the current iterate is feasible to tolerances.\n",
    "# Generally, we don't recommend using this feature since small steps\n",
    "# are not necessarily indicative of being near a stationary point,\n",
    "# particularly for nonsmooth problems.\n",
    "\n",
    "# Termination Code 1\n",
    "# opts.rel_tol = 1e-2 # default 0\n",
    "\n",
    "# Tolerance for how small of a step the line search will attempt\n",
    "# before terminating.\n",
    "\n",
    "# Termination Code 6 or 7\n",
    "# opts.step_tol = 1e-6 # default 1e-12\n",
    "# opts.step_tol = 1e-3\n",
    "\n",
    "# Acceptable total violation tolerance of the equality constraints.\n",
    "# opts.viol_eq_tol = 1e-12# default 1e-6, make it smaller will make current point harder to be considered as feasible\n",
    "\n",
    "# Quit if the elapsed clock time in seconds exceeds this. unit: second\n",
    "# opts.maxclocktime = 1.\n",
    "\n",
    "# Number of characters wide to print values for the penalty function,\n",
    "# the objective function, and the total violations of the inequality \n",
    "# and equality constraints. \n",
    "# opts.print_width = 9\n",
    "\n",
    "# PyGRANSO's uses orange\n",
    "# printing to highlight pertinent information.  However, the user\n",
    "# is the given option to disable it, since support cannot be\n",
    "# guaranteed (since it is an undocumented feature).\n",
    "# opts.print_use_orange = False\n",
    "\n",
    "# opts.init_step_size = 1e-2\n",
    "# opts.search_direction_rescaling = True\n",
    "\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn,user_opts = opts)\n",
    "print(max(abs(soln.final.x))) # should be close to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-african",
   "metadata": {},
   "source": [
    "**(For Advanced User)** Users can specify analytical gradients instead of using the auto-differentiation feature. Please check the documentation in `pygranso.py` on the required format of `combined_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without AD\n",
    "def comb_fn(X_struct):\n",
    "    q = X_struct.q\n",
    "\n",
    "    # objective function\n",
    "    qtY = q.T @ Y\n",
    "    f = 1/m * torch.norm(qtY, p = 1).item()\n",
    "    f_grad = 1/m*Y@torch.sign(Y.T@q)\n",
    "\n",
    "    # inequality constraint, matrix form\n",
    "    ci = None\n",
    "    ci_grad = None\n",
    "\n",
    "    # equality constraint \n",
    "    ce = q.T @ q - 1\n",
    "    ce_grad = 2*q\n",
    "\n",
    "    return [f,f_grad,ci,ci_grad,ce,ce_grad]\n",
    "\n",
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "opts.maxit = 500\n",
    "np.random.seed(1)\n",
    "x0 = norm.ppf(np.random.rand(n,1))\n",
    "x0 /= la.norm(x0,2)\n",
    "opts.x0 = torch.from_numpy(x0).to(device=device, dtype=torch.double)\n",
    "opts.print_frequency = 10\n",
    "opts.globalAD = False # disable global auto-differentiation\n",
    "\n",
    "start = time.time()\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn,user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))\n",
    "print(max(abs(soln.final.x))) # should be close to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-johnson",
   "metadata": {},
   "source": [
    "**(For Advanced User)** Alternatively, users can use the auto-differentiation feature partially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the AD function\n",
    "from pygranso.private.tensor2vec import getCiGradVec\n",
    "\n",
    "# partial AD\n",
    "def comb_fn(X_struct):\n",
    "    q = X_struct.q\n",
    "    q.requires_grad_(True)\n",
    "\n",
    "    # objective function\n",
    "    q_tmp = q.detach().clone()\n",
    "    qtY = q_tmp.T @ Y\n",
    "    f = 1/m * torch.norm(qtY, p = 1).item()\n",
    "    f_grad = 1/m*Y@torch.sign(Y.T@q_tmp)\n",
    "\n",
    "    # inequality constraint, matrix form\n",
    "    ci = None\n",
    "    ci_grad = None\n",
    "\n",
    "    # equality constraint \n",
    "    ce = q.T @ q - 1\n",
    "    # ce_grad = 2*q\n",
    "    ce_grad = getCiGradVec(nvar=n,nconstr_ci_total=1,var_dim_map=var_in,X=X_struct,ci_vec_torch=ce,torch_device=device,double_precision=torch.double)\n",
    "\n",
    "    # return value must be detached from the computational graph\n",
    "    ce = ce.detach()\n",
    "\n",
    "    return [f,f_grad,ci,ci_grad,ce,ce_grad]\n",
    "\n",
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "opts.maxit = 500\n",
    "np.random.seed(1)\n",
    "x0 = norm.ppf(np.random.rand(n,1))\n",
    "x0 /= la.norm(x0,2)\n",
    "opts.x0 = torch.from_numpy(x0).to(device=device, dtype=torch.double)\n",
    "opts.print_frequency = 10\n",
    "opts.globalAD = False # disable global auto-differentiation\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn,user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))\n",
    "print(max(abs(soln.final.x))) # should be close to 1**(For Advanced User)** Users can specify analytical gradients instead of using the AD feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-neutral",
   "metadata": {},
   "source": [
    "## Different Set-Up\n",
    "\n",
    "**(Optional)** Using torch.nn to set up the user-provided function. This setting is important in solving constrained deep learning problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-scope",
   "metadata": {},
   "source": [
    "### Modules Importing\n",
    "Import all necessary modules and add PyGRANSO src folder to system path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy.linalg as la\n",
    "from scipy.stats import norm\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct\n",
    "\n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-interview",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "Specify torch device, create torch model and generate data\n",
    "\n",
    "Use GPU for this problem. If no cuda device available, please set device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "class Dict_Learning(nn.Module):\n",
    "    \n",
    "    def __init__(self,n):\n",
    "        super().__init__()\n",
    "        np.random.seed(1)\n",
    "        q0 = norm.ppf(np.random.rand(n,1))\n",
    "        q0 /= la.norm(q0,2)\n",
    "        self.q = nn.Parameter( torch.from_numpy(q0) )\n",
    "    \n",
    "    def forward(self, Y,m):\n",
    "        qtY = self.q.T @ Y\n",
    "        f = 1/m * torch.norm(qtY, p = 1)\n",
    "        return f\n",
    "\n",
    "## Data initialization\n",
    "n = 30\n",
    "np.random.seed(1)\n",
    "m = 10*n**2   # sample complexity\n",
    "theta = 0.3   # sparsity level\n",
    "Y = norm.ppf(np.random.rand(n,m)) * (norm.ppf(np.random.rand(n,m)) <= theta)  # Bernoulli-Gaussian model\n",
    "# All the user-provided data (vector/matrix/tensor) must be in torch tensor format.\n",
    "# As PyTorch tensor is single precision by default, one must explicitly set `dtype=torch.double`.\n",
    "# Also, please make sure the device of provided torch tensor is the same as opts.torch_device.\n",
    "Y = torch.from_numpy(Y).to(device=device, dtype=torch.double)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = Dict_Learning(n).to(device=device, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-brother",
   "metadata": {},
   "source": [
    "### Function Set-Up\n",
    "Encode the optimization variables, and objective and constraint functions.\n",
    "\n",
    "Note: please strictly follow the format of comb_fn, which will be used in the PyGRANSO main algortihm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_fn(model,Y,m):\n",
    "    # objective function    \n",
    "    f = model(Y,m)\n",
    "\n",
    "    q = list(model.parameters())[0]\n",
    "\n",
    "    # inequality constraint\n",
    "    ci = None\n",
    "\n",
    "    # equality constraint \n",
    "    ce = pygransoStruct()\n",
    "    ce.c1 = q.T @ q - 1\n",
    "\n",
    "    return [f,ci,ce]\n",
    "\n",
    "comb_fn = lambda model : user_fn(model,Y,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-wellington",
   "metadata": {},
   "source": [
    "### User Options\n",
    "Specify user-defined options for PyGRANSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "opts.maxit = 500\n",
    "np.random.seed(1)\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "\n",
    "opts.print_frequency = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-invasion",
   "metadata": {},
   "source": [
    "### Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "soln = pygranso(var_spec= model, combined_fn = comb_fn, user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))\n",
    "print(max(abs(soln.final.x))) # should be close to 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "materialmind",
   "language": "python",
   "name": "materialmind"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
