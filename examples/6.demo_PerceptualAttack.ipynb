{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5257bb27",
   "metadata": {},
   "source": [
    "# Perceptual Attack\n",
    "\n",
    "This notebook contains examples of how to solve perceptual attack problems \n",
    "\n",
    "Reference: Laidlaw, Cassidy, Sahil Singla, and Soheil Feizi. \"Perceptual adversarial robustness: Defense against unseen threat models.\" arXiv preprint arXiv:2006.12655 (2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4364b1e6",
   "metadata": {},
   "source": [
    "## Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f7377",
   "metadata": {},
   "source": [
    "Given classifier $f$ which could map input image $x \\in X$ to labels $y = f(x) \\in Y$0. The goal of neural perceptual attack is to find an input $\\tilde{x}$ that is perceptually similar to the original input $x$ but can fool the classifier $f$, which can be formulated as:\n",
    "\n",
    "$$\\max_{\\tilde{x}} L (f(\\tilde{x}),y),$$\n",
    "$$\\text{s.t.}\\;\\; d(x,\\tilde{x}) = ||\\phi(x) - \\phi (\\tilde{x}) ||_{2} \\leq \\epsilon$$\n",
    "Here $$L (f({x}),y) = \\max_{i\\neq y} (z_i(x) - z_y(x) ),$$\n",
    "where $z_i(x)$ is the $i$-th logit output of $f(x)$, and $\\phi(\\cdot)$ is a function that could map the input $x$ to  normalized, flattened activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfdd50",
   "metadata": {},
   "source": [
    "## Import all necessary modules and add PyGRANSO src folder to system path. \n",
    "\n",
    "NOTE: perceptual advex source code (https://github.com/cassidylaidlaw/perceptual-advex.git) are required to calculate the lpips distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ed32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import sys\n",
    "## Adding PyGRANSO directories. Should be modified by user\n",
    "sys.path.append('/home/buyun/Documents/GitHub/PyGRANSO')\n",
    "from pygranso import pygranso\n",
    "from pygransoStruct import Options, Data, GeneralStruct \n",
    "from private.getNvar import getNvarTorch\n",
    "\n",
    "sys.path.append('/home/buyun/Documents/GitHub/perceptual-advex')\n",
    "from perceptual_advex.utilities import get_dataset_model\n",
    "from perceptual_advex.perceptual_attacks import get_lpips_model\n",
    "from perceptual_advex.distances import normalize_flatten_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a1b7fe",
   "metadata": {},
   "source": [
    "## Specify torch device, neural network architecture, and generate data.\n",
    "\n",
    "NOTE: please specify path for downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4842e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/home/buyun/Documents/GitHub/perceptual-advex/data/checkpoints/cifar_pgd_l2_1.pt'\n",
      "==> Preparing dataset cifar..\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "dataset, model = get_dataset_model(\n",
    "dataset='cifar',\n",
    "arch='resnet50',\n",
    "checkpoint_fname='/home/buyun/Documents/GitHub/perceptual-advex/data/checkpoints/cifar_pgd_l2_1.pt',\n",
    ")\n",
    "model = model.to(device=device, dtype=torch.double)\n",
    "# Create a validation set loader.\n",
    "batch_size = 1\n",
    "_, val_loader = dataset.make_loaders(1, batch_size, only_val=True, shuffle_val=False)\n",
    "\n",
    "inputs, labels = next(iter(val_loader))\n",
    "inputs = inputs.to(device=device, dtype=torch.double)\n",
    "labels = labels.to(device=device)\n",
    "lpips_model = get_lpips_model('alexnet_cifar', model).to(device=device, dtype=torch.double)\n",
    "\n",
    "# attack_type = 'L_2'\n",
    "# attack_type = 'L_inf'\n",
    "attack_type = 'Perceptual'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80716b",
   "metadata": {},
   "source": [
    "## Spceify optimization variables and corresponding objective and constrained function.\n",
    "\n",
    "Note: please strictly follow the format of evalObjFunction and combinedFunction, which will be used in the PyGRANSO main algortihm. *X_struct* and *data_in* are always required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb360e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables and corresponding dimensions.\n",
    "var_in = {\"x_tilde\": list(inputs.shape)}\n",
    "\n",
    "def MarginLoss(logits,labels):\n",
    "    correct_logits = torch.gather(logits, 1, labels.view(-1, 1))\n",
    "    max_2_logits, argmax_2_logits = torch.topk(logits, 2, dim=1)\n",
    "    top_max, second_max = max_2_logits.chunk(2, dim=1)\n",
    "    top_argmax, _ = argmax_2_logits.chunk(2, dim=1)\n",
    "    labels_eq_max = top_argmax.squeeze().eq(labels).float().view(-1, 1)\n",
    "    labels_ne_max = top_argmax.squeeze().ne(labels).float().view(-1, 1)\n",
    "    max_incorrect_logits = labels_eq_max * second_max + labels_ne_max * top_max\n",
    "    loss = -(max_incorrect_logits - correct_logits).clamp(max=1).squeeze().sum()\n",
    "    return loss\n",
    "\n",
    "def evalObjFunction(X_struct):\n",
    "    adv_inputs = X_struct.x_tilde\n",
    "    adv_inputs.requires_grad_(True)\n",
    "    \n",
    "    # objective function\n",
    "    logits_outputs = model(adv_inputs)\n",
    "\n",
    "    f = MarginLoss(logits_outputs,labels)\n",
    "    return f\n",
    "\n",
    "def combinedFunction(X_struct):\n",
    "    adv_inputs = X_struct.x_tilde\n",
    "    adv_inputs.requires_grad_(True)\n",
    "    \n",
    "    # objective function\n",
    "    # 8/255 for L_inf, 1 for L_2, 0.5 for PPGD/LPA\n",
    "    if attack_type == 'L_2':\n",
    "        epsilon = 1\n",
    "    elif attack_type == 'L_inf':\n",
    "        epsilon = 8/255\n",
    "    else:\n",
    "        epsilon = 0.5\n",
    "\n",
    "    logits_outputs = model(adv_inputs)\n",
    "\n",
    "    f = MarginLoss(logits_outputs,labels)\n",
    "\n",
    "    # inequality constraint, matrix form\n",
    "    # ci = None\n",
    "    ci = GeneralStruct()\n",
    "    if attack_type == 'L_2':\n",
    "        ci.c1 = torch.norm((inputs - adv_inputs).reshape(inputs.size()[0], -1)) - epsilon\n",
    "    elif attack_type == 'L_inf':\n",
    "        ci.c1 = torch.norm((inputs - adv_inputs).reshape(inputs.size()[0], -1), float('inf')) - epsilon\n",
    "    else:\n",
    "        input_features = normalize_flatten_features( lpips_model.features(inputs)).detach()\n",
    "        adv_features = lpips_model.features(adv_inputs)\n",
    "        adv_features = normalize_flatten_features(adv_features)\n",
    "        lpips_dists = (adv_features - input_features).norm(dim=1)\n",
    "        ci.c1 = lpips_dists - epsilon\n",
    "    \n",
    "    # equality constraint \n",
    "    ce = None\n",
    "\n",
    "    return [f,ci,ce]\n",
    "\n",
    "obj_eval_fn = lambda X_struct: evalObjFunction(X_struct)\n",
    "comb_fn = lambda X_struct: combinedFunction(X_struct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f55ace",
   "metadata": {},
   "source": [
    "## Specify user-defined options for PyGRANSO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a65b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = Options()\n",
    "opts.QPsolver = 'osqp'\n",
    "opts.maxit = 100\n",
    "opts.opt_tol = 1e-6\n",
    "opts.fvalquit = 1e-6\n",
    "opts.print_level = 1\n",
    "opts.print_frequency = 10\n",
    "opts.x0 = torch.reshape(inputs,(torch.numel(inputs),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca18c7",
   "metadata": {},
   "source": [
    "## Run main algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632976b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buyun/anaconda3/envs/cuosqp_pygranso/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    ║ \n",
      "Version 1.1.0                                                                                                    ║ \n",
      "MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   3072                                                                     ║ \n",
      " # of inequality constraints        :      1                                                                     ║ \n",
      " # of equality constraints          :      0                                                                     ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  0.50909392739 ║  0.50909392739 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.752374   ║ \n",
      "  10 ║ 1.000000 │ -0.55110318737 ║ -0.89901601712 ║ 0.347913 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.500435   ║ \n",
      "  20 ║ 1.000000 │ -0.96465293547 ║ -0.97820945369 ║ 0.013557 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.115001   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║ -1.00000000000 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║ -1.00000000000 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║ -1.00000000000 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              22                                                                                      ║ \n",
      "Function evaluations:    32                                                                                      ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "Total Wall Time: 4.704223394393921s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "soln = pygranso(combinedFunction = comb_fn, objEvalFunction = obj_eval_fn,var_dim_map = var_in, torch_device = device, user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc1ca84",
   "metadata": {},
   "source": [
    "6. Apply attack on multiple images by repeating above steps and calculate the successful rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49584c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 9\n",
      "\n",
      "\n",
      "\n",
      " model train acc on the original image = 1.0\n",
      "Success rate of attack = 1.0\n",
      "Average distance between attacked image and original image = 0.49303066117796535\n",
      "Average run time of PyGRANSO = 4.13142683506012s, mean f_eval = 32.0 iters\n"
     ]
    }
   ],
   "source": [
    "total_count = 10\n",
    "total_diff = 0\n",
    "original_count = 0\n",
    "attack_count = 0\n",
    "total_time = 0\n",
    "total_iterations = 0  \n",
    "\n",
    "for i in range(total_count):\n",
    "    # Get a batch from the validation set.\n",
    "    inputs, labels = next(iter(val_loader))\n",
    "    inputs = inputs.to(device=device, dtype=torch.double)\n",
    "    labels = labels.to(device=device)\n",
    "\n",
    "    # variables and corresponding dimensions.\n",
    "    var_in = {\"x_tilde\": list(inputs.shape)}\n",
    "\n",
    "    opts.x0 = torch.reshape(inputs,(torch.numel(inputs),1))\n",
    "    # suppress output\n",
    "    opts.print_level = 0\n",
    "\n",
    "    pred_labels = model(inputs).argmax(1)\n",
    "    if pred_labels == labels:\n",
    "        original_count += 1\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    start = time.time()\n",
    "    soln = pygranso(combinedFunction = comb_fn, objEvalFunction = obj_eval_fn,var_dim_map = var_in, torch_device = device, user_opts = opts)\n",
    "    end = time.time()\n",
    "    print(\"i = %d\"%i)\n",
    "    \n",
    "    total_time += end - start\n",
    "    total_iterations += soln.fn_evals\n",
    "\n",
    "    final_adv_input = torch.reshape(soln.final.x,inputs.shape)\n",
    "    pred_labels2 = model(final_adv_input.to(device=device, dtype=torch.double)).argmax(1)\n",
    "\n",
    "    if pred_labels2 == labels:\n",
    "        attack_count += 1\n",
    "        \n",
    "    if attack_type == 'L_2':\n",
    "            diff = torch.norm((inputs.to(device=device, dtype=torch.double) - final_adv_input).reshape(inputs.size()[0], -1))\n",
    "    elif attack_type == 'L_inf':\n",
    "        diff = ( torch.norm((inputs.to(device=device, dtype=torch.double) - final_adv_input).reshape(inputs.size()[0], -1), float('inf') ) )\n",
    "    else:\n",
    "        input_features = normalize_flatten_features( lpips_model.features(inputs)).detach()\n",
    "        adv_features = lpips_model.features(final_adv_input)\n",
    "        adv_features = normalize_flatten_features(adv_features)\n",
    "        lpips_dists = torch.mean((adv_features - input_features).norm(dim=1))\n",
    "        diff = lpips_dists\n",
    "\n",
    "    total_diff += diff\n",
    "\n",
    "print(\"\\n\\n\\n model train acc on the original image = {}\".format(( original_count/total_count )))\n",
    "print(\"Success rate of attack = {}\".format( (original_count-attack_count)/original_count ))\n",
    "print(\"Average distance between attacked image and original image = {}\".format(total_diff/original_count))\n",
    "print(\"Average run time of PyGRANSO = {}s, mean f_eval = {} iters\".format(total_time/original_count,total_iterations/original_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
