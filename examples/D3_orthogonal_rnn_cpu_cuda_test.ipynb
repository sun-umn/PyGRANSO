{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spatial-writer",
   "metadata": {},
   "source": [
    "# Orthogonal RNN\n",
    "\n",
    "Train Orthogonal RNN for MNIST classification based on [this Paper](https://arxiv.org/pdf/1901.08428.pdf)\n",
    "\n",
    "NOTE: this example is still under development. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-banner",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-spirituality",
   "metadata": {},
   "source": [
    "For each element in the input sequence, each layer computes the following function:\n",
    "$$h_t=\\tanh(W_{ih}x_t+b_{ih}+W_{hh}h_{t-1}+b_hh)$$\n",
    "\n",
    "where $h_{t}$ is the hidden state at time $t$, and $h_{t-1}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $o$. \n",
    "\n",
    "For each layer, we have the orthogonal constraint:\n",
    "$$ W_{hh}^T W_{hh} = I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-bangladesh",
   "metadata": {},
   "source": [
    "## Modules Importing\n",
    "Import all necessary modules and add PyGRANSO src folder to system path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collect-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import sys\n",
    "## Adding PyGRANSO directories. Should be modified by user\n",
    "sys.path.append('/users/5/dever120/PyGRANSO')\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct \n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from pygranso.private.getObjGrad import getObjGradDL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-luxembourg",
   "metadata": {},
   "source": [
    "## Data Initialization \n",
    "Specify torch device, neural network architecture, and generate data.\n",
    "\n",
    "NOTE: please specify path for downloading data.\n",
    "\n",
    "Use GPU for this problem. If no cuda device available, please set *device = torch.device('cpu')*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "diverse-research",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error downloading train-images-idx3-ubyte.gz:\nTried https://ossci-datasets.s3.amazonaws.com/mnist/, got:\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1032)>\nTried http://yann.lecun.com/exdb/mnist/, got:\nHTTP Error 404: Not Found\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=double_precision)\n\u001b[32m     39\u001b[39m model.train()\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m train_data = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/users/5/dever120/examples/data/mnist\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                         \u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m)\u001b[49m \n\u001b[32m     48\u001b[39m loaders = {\n\u001b[32m     49\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m : torch.utils.data.DataLoader(\n\u001b[32m     50\u001b[39m         train_data, \n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m     ),\n\u001b[32m     55\u001b[39m }\n\u001b[32m     57\u001b[39m inputs, labels = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(loaders[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyGRANSO/.venv/lib/python3.13/site-packages/torchvision/datasets/mnist.py:100\u001b[39m, in \u001b[36mMNIST.__init__\u001b[39m\u001b[34m(self, root, train, transform, target_transform, download)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_exists():\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyGRANSO/.venv/lib/python3.13/site-packages/torchvision/datasets/mnist.py:197\u001b[39m, in \u001b[36mMNIST.download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mirror, err \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.mirrors, errors):\n\u001b[32m    196\u001b[39m     s += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTried \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmirror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(err)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(s)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error downloading train-images-idx3-ubyte.gz:\nTried https://ossci-datasets.s3.amazonaws.com/mnist/, got:\n<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1032)>\nTried http://yann.lecun.com/exdb/mnist/, got:\nHTTP Error 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 30\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "double_precision = torch.double\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x,(batch_size,sequence_length,input_size))\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(\n",
    "            self.num_layers,\n",
    "            x.size(0),\n",
    "            self.hidden_size\n",
    "        ).to(device=device, dtype=double_precision)\n",
    "        out, hidden = self.rnn(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=double_precision)\n",
    "model.train()\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='/users/5/dever120/examples/data/mnist',\n",
    "    train=True,                         \n",
    "    transform=ToTensor(), \n",
    "    download=True,            \n",
    ") \n",
    "\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(\n",
    "        train_data, \n",
    "        batch_size=100, \n",
    "        shuffle=True, \n",
    "        num_workers=1\n",
    "    ),\n",
    "}\n",
    "\n",
    "inputs, labels = next(iter(loaders['train']))\n",
    "inputs, labels = inputs.reshape(\n",
    "    -1, sequence_length, input_size\n",
    ").to(device=device, dtype=double_precision), labels.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-outreach",
   "metadata": {},
   "source": [
    "## Function Set-Up\n",
    "\n",
    "Encode the optimization variables, and objective and constraint functions.\n",
    "\n",
    "Note: please strictly follow the format of comb_fn, which will be used in the PyGRANSO main algortihm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_fn(model,inputs,labels):\n",
    "    # objective function    \n",
    "    logits = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    f = criterion(logits, labels)\n",
    "\n",
    "    A = list(model.parameters())[1]\n",
    "\n",
    "    # inequality constraint\n",
    "    ci = None\n",
    "\n",
    "    # equality constraint \n",
    "    # special orthogonal group\n",
    "    \n",
    "    ce = pygransoStruct()\n",
    "\n",
    "    c1_vec = (\n",
    "        A.T @ A - torch.eye(hidden_size).to(\n",
    "            device=device, dtype=double_precision\n",
    "        )\n",
    "    ).reshape(1, -1)\n",
    "    \n",
    "    ce.c1 = torch.linalg.vector_norm(c1_vec, 2) # l2 folding to reduce the total number of constraints\n",
    "\n",
    "    return [f, ci, ce]\n",
    "\n",
    "comb_fn = lambda model : user_fn(model, inputs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-interpretation",
   "metadata": {},
   "source": [
    "## User Options\n",
    "Specify user-defined options for PyGRANSO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar, 1)\n",
    "opts.opt_tol = 1e-3\n",
    "opts.viol_eq_tol = 1e-4\n",
    "opts.print_level = 1\n",
    "opts.print_frequency = 50\n",
    "opts.double_precision = True\n",
    "\n",
    "opts.mu0 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-documentary",
   "metadata": {},
   "source": [
    "## Initial Test \n",
    "Check initial accuracy of the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Initial acc = {:.2f}%\".format((100 * correct / len(inputs))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-boring",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cpu_soln = pygranso(var_spec=model, combined_fn=comb_fn, user_opts=opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-february",
   "metadata": {},
   "source": [
    "## Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.utils.vector_to_parameters(cpu_soln.final.x, model.parameters())\n",
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Final acc = {:.2f}%\".format((100 * correct / len(inputs))))  \n",
    "print(\"final feasibility = {}\".format(cpu_soln.final.tve))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-asian",
   "metadata": {},
   "source": [
    "## CUDA Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 30\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "double_precision = torch.double\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x,(batch_size,sequence_length,input_size))\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(\n",
    "            self.num_layers,\n",
    "            x.size(0),\n",
    "            self.hidden_size\n",
    "        ).to(device=device, dtype=double_precision)\n",
    "        out, hidden = self.rnn(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=double_precision)\n",
    "model.train()\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='/users/5/dever120/examples/data/mnist',\n",
    "    train=True,                         \n",
    "    transform=ToTensor(), \n",
    "    download=True,            \n",
    ") \n",
    "\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(\n",
    "        train_data, \n",
    "        batch_size=100, \n",
    "        shuffle=True, \n",
    "        num_workers=1\n",
    "    ),\n",
    "}\n",
    "\n",
    "inputs, labels = next(iter(loaders['train']))\n",
    "inputs, labels = inputs.reshape(\n",
    "    -1, sequence_length, input_size\n",
    ").to(device=device, dtype=double_precision), labels.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_fn(model,inputs,labels):\n",
    "    # objective function    \n",
    "    logits = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    f = criterion(logits, labels)\n",
    "\n",
    "    A = list(model.parameters())[1]\n",
    "\n",
    "    # inequality constraint\n",
    "    ci = None\n",
    "\n",
    "    # equality constraint \n",
    "    # special orthogonal group\n",
    "    \n",
    "    ce = pygransoStruct()\n",
    "\n",
    "    c1_vec = (\n",
    "        A.T @ A - torch.eye(hidden_size).to(\n",
    "            device=device, dtype=double_precision\n",
    "        )\n",
    "    ).reshape(1,-1)\n",
    "    \n",
    "    ce.c1 = torch.linalg.vector_norm(c1_vec, 2) # l2 folding to reduce the total number of constraints\n",
    "\n",
    "    return [f, ci, ce]\n",
    "\n",
    "comb_fn = lambda model : user_fn(model, inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_fn(model,inputs,labels):\n",
    "    # objective function    \n",
    "    logits = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    f = criterion(logits, labels)\n",
    "\n",
    "    A = list(model.parameters())[1]\n",
    "\n",
    "    # inequality constraint\n",
    "    ci = None\n",
    "\n",
    "    # equality constraint \n",
    "    # special orthogonal group\n",
    "    \n",
    "    ce = pygransoStruct()\n",
    "\n",
    "    c1_vec = (\n",
    "        A.T @ A - torch.eye(hidden_size).to(\n",
    "            device=device, dtype=double_precision\n",
    "        )\n",
    "    ).reshape(1, -1)\n",
    "    \n",
    "    ce.c1 = torch.linalg.vector_norm(c1_vec, 2) # l2 folding to reduce the total number of constraints\n",
    "\n",
    "    return [f, ci, ce]\n",
    "\n",
    "comb_fn = lambda model : user_fn(model, inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar, 1)\n",
    "opts.opt_tol = 1e-3\n",
    "opts.viol_eq_tol = 1e-4\n",
    "opts.print_level = 1\n",
    "opts.print_frequency = 50\n",
    "opts.double_precision = True\n",
    "\n",
    "opts.mu0 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Initial acc = {:.2f}%\".format((100 * correct / len(inputs)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cuda_soln = pygranso(var_spec=model, combined_fn=comb_fn, user_opts=opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.utils.vector_to_parameters(cuda_soln.final.x, model.parameters())\n",
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Final acc = {:.2f}%\".format((100 * correct / len(inputs))))  \n",
    "print(\"final feasibility = {}\".format(cuda_soln.final.tve))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-procurement",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(\n",
    "    cpu_soln.final.x,\n",
    "    cuda_soln.final.x.cpu(),\n",
    "    atol=1e-6,\n",
    "    rtol=1e-6,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimization",
   "language": "python",
   "name": "optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
